{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f97a35",
   "metadata": {},
   "source": [
    "# Quantile universal threshold\n",
    "---\n",
    "**Aymen.B**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a804c2c",
   "metadata": {},
   "source": [
    "Je me repose sur l'article *\"Quantile universal threshold: model selection at the detection edge for high-dimensional linear regression\"* de **Jairo Diaz Rodriguez** et **Sylvain Sardy**\n",
    "\n",
    "Ainsi que sur celui-ci *\"Quantile universal threshold for model selection\"* de **Caroline Giacobino**, **Sylvain Sardy**, **Jairo Diaz Rodriguez** et **Nick Hengartner**\n",
    "\n",
    "et enfin ce dernier *\"Training a neural network for data interpretation and better generalization: towards intelligent artificial intelligence\"* de **Sylvain Sardy**, **Maxime van Custsem** et **Xiaoyu Ma**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d34ab6",
   "metadata": {},
   "source": [
    "## Théorie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca2ba6",
   "metadata": {},
   "source": [
    "### La fonction zero-thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2441e",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    ">**Définition 1.** \n",
    ">\n",
    ">Supposons que $Y \\sim f_{\\xi_0}$. Un estimateur $\\hat{\\xi}_\\lambda(Y)$ indexé par $\\lambda \\geq 0$ est appelé un estimateur thresholding si\n",
    ">\n",
    ">$$\n",
    ">\\mathbb{P}(\\hat{\\xi}_\\lambda(Y) = 0) > 0 \\quad \\text{pour un certain } \\lambda \\text{ fini}.\n",
    ">$$\n",
    "\n",
    "Notez que la régression ridge n'est pas un estimateur thresholding car $\\hat{\\xi}_\\lambda(y) \\neq 0$ pour tout $\\lambda$ fini et tout $\\mathbf{y} \\in \\mathbb{R}^n$. C’est dû au fait que la pénalité $\\ell_2$ ne force pas de composantes à zéro.\n",
    "\n",
    ">**Définition 2.** \n",
    ">\n",
    ">Un estimateur thresholding $\\hat{\\xi}_\\lambda(Y)$ admet une fonction zero-thresholding $\\lambda_0(Y)$ si\n",
    ">\n",
    ">$$\n",
    ">\\hat{\\xi}_\\lambda(Y) = 0 \\quad \\Leftrightarrow \\quad \\lambda \\geq \\lambda_0(Y) \\quad \\text{presque partout}.\n",
    ">$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63d099",
   "metadata": {},
   "source": [
    ">**Définition 3.**  \n",
    ">\n",
    ">On définit la **fonction de zero-thresholding locale** $\\lambda_0^{\\text{local}}(Y)$ étant le plus petit $\\lambda$ tel que la solution nulle soit **un minimum local** du critère régularisé (et non forcément global $\\lambda_0(Y)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8252ba0",
   "metadata": {},
   "source": [
    "Dans le cas convexe, on a $\\boxed{\\lambda_0^{\\text{local}}(Y) = \\lambda_0(Y)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb148cc",
   "metadata": {},
   "source": [
    "#### Trouver $\\lambda_0(\\cdot)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170c2b7",
   "metadata": {},
   "source": [
    "Donc $\\lambda_0(Y)$ est le plus petit $\\lambda$ pour lequel la solution $\\hat{\\xi}_\\lambda(Y) = 0$\n",
    "\n",
    "Il s'agit donc d'identifier la plus petite valeur $\\lambda$ telle que l’estimateur annule tous les paramètres, c’est-à-dire que la solution $\\hat{\\xi}_\\lambda(Y) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9153d51a",
   "metadata": {},
   "source": [
    "##### **Exemple LASSO :** ($\\xi = \\beta$)\n",
    "\n",
    "On cherche pour quel $\\lambda$ la solution du problème  \n",
    "$$\n",
    "\\hat{\\beta}_\\lambda(y) = \\arg\\min_{\\beta}\\frac{1}{2n}\\|y-X\\beta\\|_2^2+\\lambda\\|\\beta\\|_1\n",
    "$$\n",
    "devient nulle.\n",
    "\n",
    "Calcul du gradient au point $\\beta=0$ :\n",
    "\n",
    "(ici la sous-différentielle car pas possible d'avoir le gradient partout)\n",
    "$$\n",
    "-\\frac{1}{n} X^\\top y + \\lambda \\cdot \\partial \\|\\beta\\|_1\n",
    "$$\n",
    "\n",
    "Pour que $\\hat{\\beta}_\\lambda(y) = 0$ soit minimum, il faut que :\n",
    "\n",
    "(Quand la fonction n’est pas différentiable partout, on remplace la condition\n",
    "“le gradient est nul” par la condition “0 est dans la sous-différentielle”)\n",
    "$$\n",
    "0 \\in -\\frac{1}{n} X^\\top y + \\lambda \\cdot \\partial \\|\\beta\\|_1 \\quad \\text{en} \\quad \\beta=0\n",
    "$$\n",
    "Soit\n",
    "$$\n",
    "\\frac{1}{n}X^\\top y \\in \\lambda \\cdot \\partial \\|\\beta\\|_1\n",
    "$$\n",
    "Or,\n",
    "$$\\|\\beta\\|_1=\\sum_{j=1}^p|\\beta_j|$$\n",
    "et\n",
    "$$\\partial|x|= \\text{Cste} \\in [-1,1] \\quad \\text{avec la sous-différentiel au point} \\quad \\beta=0$$\n",
    "Donc :\n",
    "$$\\partial\\|\\beta\\|_1=\\{v\\in\\mathbb{R}^p:v_j\\in[-1,1]\\text{ pour tout }j\\} \\quad \\text{au point} \\quad \\beta = 0$$\n",
    "\n",
    "Ainsi :\n",
    "$$\n",
    "\\frac{1}{n}X^\\top y\\in\\lambda\\cdot\\partial\\|\\beta\\|_1 \\quad\\Longleftrightarrow\\quad  \\text{chaque composante de }\\frac{1}{n}X^\\top y\\text{ est dans }[-\\lambda,\\lambda] \n",
    "$$\n",
    "$$\\quad\\Longleftrightarrow\\quad \\left\\|\\frac{1}{n}X^\\top y\\right\\|_\\infty\\leq\\lambda$$\n",
    "    \n",
    "Donc :\n",
    "$$\n",
    "\\lambda_0(y) = \\left\\| \\frac{1}{n} X^\\top y \\right\\|_\\infty\n",
    "$$\n",
    "\n",
    "[C'est quoi la sous-différentiel ?](https://fr.wikipedia.org/wiki/Sous-diff%C3%A9rentiel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8fdd6",
   "metadata": {},
   "source": [
    "### Le \"Quantile Universal Threshold\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5510a",
   "metadata": {},
   "source": [
    ">**Définition 4.**\n",
    ">\n",
    ">Toutes les pénalités ne permettent pas d’appliquer la méthode du QUT. \n",
    ">\n",
    ">On dit qu’une pénalité est **QUT-compatible** si la fonction $\\lambda_0(Y)$ (ou $\\lambda_0^{\\text{local}}(Y)$) n’est pas constante. (ni toujours nulle ou infinie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70fa89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    ">**Définition 5.** \n",
    ">\n",
    ">Supposons que $Y \\sim f_{\\xi_0}$ et soit $\\hat{\\xi}_\\lambda(Y)$ un estimateur avec une fonction zero-thresholding associée $\\lambda_0(\\cdot)$. \n",
    ">\n",
    ">Posons $\\Lambda := \\lambda_0(\\mathbf{Y}_0)$, où $\\mathbf{Y}_0 \\sim f_{\\xi_0}$ sous le modèle nul avec le paramètre $\\xi_0 = 0$. \n",
    ">\n",
    ">Le quantile universal threshold $\\lambda^{\\mathrm{QUT}}$ est le quantile supérieur $(1-\\alpha)$ de la statistique de thresholding $\\Lambda$, à savoir\n",
    ">\n",
    ">$$\n",
    ">\\lambda^{\\mathrm{QUT}} := F^{-1}_\\Lambda(1-\\alpha).\n",
    ">$$\n",
    "\n",
    ">Dans le cas non convexe, on utilise la fonction $\\lambda_0^{\\text{local}}(Y)$ à la place, ce qui donne :\n",
    ">$$\n",
    ">\\lambda^{\\mathrm{QUT}} := F^{-1}_{\\Lambda^{\\text{local}}}(1 - \\alpha)\n",
    ">$$\n",
    ">avec $\\Lambda^{\\text{local}} = \\lambda_0^{\\text{local}}(Y_0)$.\n",
    "\n",
    "\n",
    "On recommande de choisir $\\alpha=O(1/\\sqrt{\\log P})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53acd4",
   "metadata": {},
   "source": [
    "### Statistique pivotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7422a4",
   "metadata": {},
   "source": [
    ">**Définition 6.**\n",
    ">\n",
    ">Une statistique $\\Lambda(Y)$ est dite pivotal si sa loi ne dépend d’aucun paramètre inconnu du modèle. (comme $\\sigma^2$ ou $\\beta$ par exemple)\n",
    "\n",
    "Le QUT repose sur le fait qu’on peut simuler la loi de $\\lambda_0(Y)$ sous le modèle nul $Y \\sim f_{\\xi_0}$ avec $\\xi_0 = 0$, pour en extraire un quantile seuil.\n",
    "\n",
    "Mais pour que cette simulation soit possible, il faut que la distribution de $\\Lambda$ soit connue ou du moins indépendante des paramètres inconnus.\n",
    "\n",
    "Sinon on se retrouve obligé d'estimer ces paramètres inconnus et on perd le caractère vraiment universel de la méthode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ffec7",
   "metadata": {},
   "source": [
    "## Algorithmes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de02a9",
   "metadata": {},
   "source": [
    "### Cas du LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da2f52",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boxed{\n",
    "\\begin{array}{ll}\n",
    "\\textbf{QUT Simulation Algorithm (LASSO, oracle)} \\\\\n",
    "\\\\\n",
    "\\textbf{Step 0.} & \\text{Fixer } M \\in \\mathbb{N} \\text{ (nombre de simulations), } \\alpha \\in (0, 1), \\text{ et connaître } \\sigma^2. \\\\\n",
    "& \\text{Initialiser un vecteur } \\Lambda \\leftarrow \\emptyset. \\\\\n",
    "\\\\\n",
    "\\textbf{Step m.} & \\text{Pour } m = 1 \\text{ à } M : \\\\\n",
    "& \\quad \\text{Simuler } Y_{\\text{Sim}}^{(m)} \\sim \\mathcal{N}(0, \\sigma^2 I_n). \\\\\n",
    "& \\quad \\text{Calculer } \\lambda_0^{(m)} \\leftarrow \\left\\| \\frac{1}{n} X^\\top Y_{\\text{Sim}}^{(m)} \\right\\|_\\infty. \\\\\n",
    "& \\quad \\text{Ajouter } \\lambda_0^{(m)} \\text{ à } \\Lambda. \\\\\n",
    "\\\\\n",
    "\\textbf{Final Step.} & \\text{Définir le seuil } \\lambda^{\\text{QUT}} \\leftarrow \\text{quantile}_{1 - \\alpha}(\\Lambda).\n",
    "\\end{array}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a39bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_tools import qut_lasso_oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afbc91",
   "metadata": {},
   "source": [
    "Cette fonction sera tester dans le cas linéaire de LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3154f",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15510a09",
   "metadata": {},
   "source": [
    "Pour savoir si notre $\\lambda_{\\text{QUT}}$ est bien estimé. On peut s'interesser aux taux de sélection sous le modèle nul.\n",
    "\n",
    "Autrement dit, on estime :\n",
    "$$\n",
    "\\hat{\\alpha} = \\mathbb{P}_{H_0} \\left( \\hat{\\xi}_{\\lambda_{\\mathrm{QUT}}}(Y) \\neq 0 \\right)\n",
    "$$\n",
    "Ce taux doit être proche de $\\alpha$ en théorie !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
