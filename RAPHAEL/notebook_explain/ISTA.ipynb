{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58abe19",
   "metadata": {},
   "source": [
    "$\\textbf{GOAL}$ : We want to get a correct ISTA algorithm converging until tolerance given (or not) L value, prox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e064553",
   "metadata": {},
   "source": [
    "*The L-lipschitz constant is known for LASSO but not $\\sqrt{LASSO}$ and surely for other $f$. So we will need **backtrack** : choose a \"large\" L and decreases (dividing by 2) over iterations and see if the loss decreases (accept so L/2).*   \n",
    "\n",
    "*The prox sera toujours donné dans ce projet car c'est un hypothèse que g soit proximable*   \n",
    "\n",
    "TODO : S'assurer de l'hyptothese + def d'être proximable (ça veut surement dire que le prox, selon g, est explicite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cb7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, Printf, Statistics, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae38996",
   "metadata": {},
   "source": [
    "# ISTA\n",
    "\n",
    "$\\textbf{Definition}$\n",
    "Let $\\gamma>0$ and convex function $g : \\mathbb{R}^n \\to \\mathbb{R}$, for $n>0$, we call proximal operator of $g$ with $\\gamma$, \n",
    "$$\n",
    "\\emph{prox}_{\\gamma, g} : v\\in \\mathbb{R}^n \\mapsto \\arg\\min_{x\\in\\mathbb R^{n}}\\;\\Bigl\\{\\,g(x)+\\tfrac1{2\\gamma}\\|x-v\\|_2^2\\Bigr\\}\n",
    "$$\n",
    "\n",
    "\n",
    "Iterative Soft-Thresholding Algorithm (ISTA) is a proximal gradient method, each iteration $(w_k)$ performs a gradient descent step on the smooth loss followed by a soft-thresholding. \n",
    "\n",
    "$\\textbf{Definition}$\n",
    "To minimize the problem $f+g$ with $f$ convex, where its differential is $L$-Lipschitz and g convex. We approximate the minimizer $w^*$ by $(w_k)_{k\\geq0}$ defined as, $w_0$ an initial point and with the update rule, for $\\gamma>0$,\n",
    "    $$\n",
    "    w^{(k+1)} \\;=\\; \\mathrm{prox}_{\\gamma, g}\\!\\Big(w_k - \\gamma\\, \\partial f(w_k) \\Big)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29555d",
   "metadata": {},
   "source": [
    "# Basic LASSO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3fc5b0",
   "metadata": {},
   "source": [
    "Let $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\mathbb{R}^{n}$\n",
    "\n",
    "$$\n",
    "\\min_{b \\in \\mathbb{R}^{p}}\n",
    "\\frac12 \\|y - X b\\|_{2}^{2}\n",
    "+ \\lambda \\|b\\|_{1}\n",
    "\\tag{LASSO}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e1963",
   "metadata": {},
   "source": [
    "So in this first case, we have a optimization problem under the form $f+g$ with $f=MSE$ and $g = \\ell_1$-norm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446cedb",
   "metadata": {},
   "source": [
    "$L = X^TX$ because \n",
    "$$\n",
    "\\|\\partial f(b) - \\partial f(a)\\|\n",
    "= \\|-X^{T}(y-X b) + X^{T}(y-X a)\\|\n",
    "= \\|X^{T}X(b - a)\\|\n",
    "\\le \\|X^{T}X\\|\\|b - a\\|$$\n",
    "\n",
    "and then we use $\\ell_2$-norm since it allows to the proximal to be explicit.  \n",
    "So we have the square of largest eigenvalue for $X^TX$ ,\n",
    "\n",
    "$$||X^TX||_2 = ||X||_2^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31954b",
   "metadata": {},
   "source": [
    "**Proximal**\n",
    "$$f : w \\mapsto \\tfrac12\\|Aw-b\\|_2^2 \\quad \\text{and} \\quad g : w \\mapsto \\lambda\\|w\\|_1$$\n",
    "For $k\\geq0$, let $u_k = w_k-\\gamma A^\\top(Aw_k-b)$. \n",
    "Then, $\\forall i\\in \\llbracket 1,n \\rrbracket$,\n",
    "$$\n",
    "w_{k+1}^{(i)}\n",
    "=\\emph{sign}\\bigl(u_k^{(i)}\\bigr)\\,\\max\\bigl(|u_k^{(i)}|-\\gamma\\lambda,0\\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfba1e",
   "metadata": {},
   "source": [
    "\n",
    "*Proof*  \n",
    "\n",
    "Since $g$ is separable we have coordinate-wise on $\\mathrm{prox}$, hence, for $i \\in \\llbracket 1,n \\rrbracket$,\n",
    "\\begin{equation}\n",
    "w_{k+1}^{(i)}\n",
    "=\\mathrm{prox}_{\\gamma,\\lambda|\\cdot|}\\bigl(u_k^{(i)}\\bigr) = \n",
    "\\arg\\min_{x\\in\\mathbb{R}} \\Bigl\\{ \\lambda|x|+\\tfrac{1}{2\\gamma}\\Bigl(x-u_k^{(i)}\\Bigr)^2\\Bigr\\} \\tag{R1}\n",
    "\\end{equation}\n",
    "\n",
    "From KKT Theorem, we denote $x^*$ the minimizer of (R1) verifying, $$0 \\in \\partial \\Bigl( x\\mapsto  \\lambda|x|+\\tfrac{1}{2\\gamma}\\Bigl(x-u_k^{(i)}\\Bigr)^ 2\\Bigr)(x^*) = \\lambda \\partial|\\cdot|_1(x^*) + \\frac{1}{\\gamma}(x^*-u_k^{(i)})$$\n",
    "\n",
    "+  $x^{*}>0 \\implies 0 = \\lambda\\cdot1 + \\tfrac{1}{\\gamma}(x^{*}-u_k^{(i)})\n",
    "   \\;\\Longleftrightarrow\\;\n",
    "   x^{*}=u_k^{(i)}-\\gamma\\lambda$ et $u_k^{(i)}>\\gamma\\lambda$\n",
    "   \n",
    "+ $x^{*}<0 \\implies 0 = \\lambda\\cdot1 + \\tfrac{1}{\\gamma}(x^{*}-u_k^{(i)})\n",
    "   \\;\\Longleftrightarrow\\;\n",
    "   x^{*}=u_k^{(i)}-\\gamma\\lambda$ et $u_k^{(i)}<-\\gamma\\lambda$\n",
    "\n",
    "+ $x^{*}=0 \\implies \n",
    "   0\\in \\lambda[-1,1] + \\tfrac{1}{\\gamma}(0-u_k^{(i)})\n",
    "   \\;\\Longrightarrow\\;\n",
    "   u_k^{(i)}\\in[-\\gamma\\lambda,\\;\\gamma\\lambda]\n",
    "   $\n",
    "\n",
    "Combining these three cases gives,\n",
    "\n",
    "$$\n",
    "w_{k+1}^{(i)}\n",
    "=x^{*}\n",
    "=\\begin{cases}\n",
    "u_k^{(i)}-\\gamma\\lambda, & u_k^{(i)}>\\gamma\\lambda\\\\\n",
    "0, & |u_k^{(i)}|\\le\\gamma\\lambda\\\\\n",
    "u_k^{(i)}+\\gamma\\lambda, & u_k^{(i)}<-\\gamma\\lambda\n",
    "\\end{cases}\n",
    "=\\mathrm{sign}\\bigl(u_k^{(i)}\\bigr)\\,\\max\\bigl\\{|u_k^{(i)}|-\\gamma\\lambda,\\;0\\bigr\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e818d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prox (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prox(x, τ) = sign(x) * max(abs(x) - τ, zero(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075fa6eb",
   "metadata": {},
   "source": [
    "### Simple (primal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b73cf",
   "metadata": {},
   "source": [
    "We run the algroithm while the difference value of the cost function (f+g) at two consecutive iteration is below than $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98f7140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ista_basic_lasso (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function ista_basic_lasso(X, y, λ, prox;\n",
    "        max_iter = 100_000, tol = 1e-9,print_freq = 1000, verbose = true\n",
    "    )\n",
    "    m, p = size(X)\n",
    "    L = opnorm(X)^2 # Lipschitz constant of ∇½‖y-Xβ‖²\n",
    "    step = 1/L #in ]0,2/L[ so linearly convergent\n",
    "    β = zeros(eltype(X), p)\n",
    "    β_next = similar(β)\n",
    "    r = copy(y) # residual\n",
    "    # Initial cost value\n",
    "    cost_prev = Inf\n",
    "    \n",
    "    for k in 1:max_iter\n",
    "        # Gradient step\n",
    "        grad = -(X' * r) # ∇½‖y-Xβ‖²\n",
    "        β_next .= prox.(β .- step .* grad, λ*step)\n",
    "        mul!(r, X, β_next)\n",
    "        @. r = y - r\n",
    "        cost_current = 0.5*dot(r,r) + λ*sum(abs, β_next)\n",
    "    \n",
    "        if abs(cost_current - cost_prev) < tol\n",
    "            β .= β_next\n",
    "            if verbose\n",
    "                @printf(\"[ISTA] END iter %5d  cost=%.3e  diff=%.3e\\n\", k, cost_current, abs(cost_current - cost_prev))\n",
    "            end\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        if verbose && (k == 1 || k % print_freq == 0)\n",
    "            @printf(\"[ISTA]  iter %5d  cost=%.3e  diff=%.3e\\n\", k, cost_current, abs(cost_current - cost_prev))\n",
    "        end\n",
    "        cost_prev = cost_current\n",
    "        β .= β_next\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return β\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e329af",
   "metadata": {},
   "source": [
    "### GAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d299ba8c",
   "metadata": {},
   "source": [
    "For my project (screen cleaning), I use ISTA until the solution was $\\epsilon$-optimal (the solution under the primal, there : $f+g$) and this is possible according to the gap function after definind the dual\n",
    "$$\n",
    "  (\\mathcal{D}_\\lambda) : \n",
    "  \\max_{u\\in\\mathbb{R}^m}\\; -\\tfrac12\\|u\\|_{2}^{2} + \\langle u,y\\rangle  \n",
    "  \\quad\\text{s.t.}\\quad \\|A^Tu\\|_\\infty\\le\\lambda$$\n",
    "\n",
    "  and we stop the algorithm when $\\mathcal{G}(x_k,u_k) := P(x_k)-D(y-Ax_k) \\leq \\epsilon$ with $u_k:=y-Ax_k$ the corresponding point in the dual from the primal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "353f212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ista_basic_lasso_gap (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function ista_basic_lasso_gap(X, y, λ, prox;\n",
    "        max_iter = 100_000,tol = 1e-9,print_freq = 1000, verbose = true\n",
    "    )\n",
    "    m, p  = size(X)\n",
    "    L = opnorm(X)^2 # Lipschitz constant of ∇½‖y-Xβ‖²\n",
    "    step = 1/L #in ]0,2/L[ so linearly convergent\n",
    "    β = zeros(eltype(X), p)\n",
    "    r = copy(y) # residual\n",
    "\n",
    "    for k in 1:max_iter\n",
    "        grad  = -(X' * r) # ∇½‖y-Xβ‖²\n",
    "        β .= prox.(β .- step .* grad, λ*step) \n",
    "        mul!(r, X, β) # r = Xβ\n",
    "        @. r = y - r\n",
    "        primal = 0.5*dot(r,r) + λ*sum(abs,β)\n",
    "        θ = r .* min(one(eltype(X)), λ / maximum(abs.(X' * r)))  # dual projection\n",
    "        dual = 0.5*dot(y,y) - 0.5*dot(y .- θ, y .- θ)\n",
    "        gap = max(primal - dual, 0.0) # >= 0\n",
    "\n",
    "        if verbose && (k == 1 || k % print_freq == 0)\n",
    "            @printf(\"[ISTA]  iter %5d  gap=%.3e\\n\", k, gap)\n",
    "        end\n",
    "        \n",
    "        if verbose && gap < tol\n",
    "            @printf(\"[ISTA] END iter %5d cost=%.3e gap=%.3e\\n\", k, primal, gap)\n",
    "            break # or return\n",
    "        end\n",
    "    end\n",
    "    return β\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26aec3",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ae2f9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n, p = 100, 50\n",
    "Random.seed!(42)\n",
    "X = randn(n, p)\n",
    "sigma = 0.1\n",
    "y = X * randn(p) + sigma * randn(n)\n",
    "λ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bfe0890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ISTA]  iter     1  cost=7.895e+02  diff=Inf\n",
      "[ISTA] END iter   259  cost=4.280e+00  diff=9.353e-10\n",
      "[ISTA]  iter     1  gap=7.876e+02\n",
      "[ISTA] END iter   672 cost=4.280e+00 gap=9.652e-10\n"
     ]
    }
   ],
   "source": [
    "beta_1 = ista_basic_lasso(X, y, λ, prox, tol=1e-9)\n",
    "beta_2 = ista_basic_lasso_gap(X, y, λ, prox, tol=1e-9)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab966b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4914334963922471e-5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maximum(abs.(beta_1 - beta_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e35b5c",
   "metadata": {},
   "source": [
    "# General function *(f, g, L, prox given)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb71509",
   "metadata": {},
   "source": [
    "Precedents functions use primal, dual which depend on f and g, so we give, inspired from the first algorithm, ISTA function with prox given and the L Lispitchz constant given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b96f12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ista_L (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function ista_L(x0, f, g, ∇f, L, prox;\n",
    "        max_iter = 100_000, tol = 1e-9,print_freq = 1000, verbose = true\n",
    "    )\n",
    "    x = copy(x0)\n",
    "    x_next = similar(x)\n",
    "    \n",
    "    step = 1/L\n",
    "    cost_prev = f(x) + g(x)\n",
    "    for k in 1:max_iter\n",
    "        grad = ∇f(x)\n",
    "        x_next .= prox(x .- step .* grad, step)\n",
    "        \n",
    "        cost_current = f(x_next) + g(x_next)\n",
    "        if abs(cost_current - cost_prev) <tol\n",
    "            x .= x_next\n",
    "            if verbose\n",
    "                @printf(\"[ISTA] END iter %5d  cost=%.3e  diff=%.3e\\n\", k, cost_current, abs(cost_current - cost_prev))\n",
    "            end\n",
    "            break\n",
    "        end\n",
    "        if verbose && (k == 1 || k % print_freq == 0)\n",
    "            @printf(\"[ISTA] iter %5d  cost=%.3e  diff=%.3e\\n\", k, cost_current, abs(cost_current - cost_prev))\n",
    "        end\n",
    "    \n",
    "        cost_prev = cost_current\n",
    "        x .= x_next\n",
    "    end\n",
    "    \n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d20b2f",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f344bd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n, p = 100, 50\n",
    "Random.seed!(42)\n",
    "X = randn(n, p)\n",
    "sigma = 0.1\n",
    "y = X * randn(p) + sigma * randn(n)\n",
    "λ = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29015814",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968cb19d",
   "metadata": {},
   "source": [
    "On est censé tombé sur les memes résultats que précédemment. C'est le cas, la différence est nulle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbed715e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ISTA] iter     1  cost=7.895e+02  diff=1.733e+03\n",
      "[ISTA] END iter   259  cost=4.280e+00  diff=9.353e-10\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `beta_1` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `beta_1` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\Le R\\Desktop\\Code\\Projets\\Geneve\\STAGE-GENEVE\\RAPHAEL\\notebook_explain\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X40sZmlsZQ==.jl:10"
     ]
    }
   ],
   "source": [
    "f(b) = 0.5*norm(y-X*b,2)^2\n",
    "∇f(b) = -X'*(y - X*b)\n",
    "g(x) = λ*sum(abs, x) # L1 norm\n",
    "prox_L(x, step) = sign.(x) .* max.(abs.(x) .- λ*step, zero(x))\n",
    "\n",
    "beta0 = zeros(p)# initial conditions\n",
    "\n",
    "beta_L = ista_L(beta0, f, g, ∇f, opnorm(X)^2, prox_L, tol=1e-9)\n",
    "\n",
    "println(\"Différence entre beta_L et beta_1 : \", maximum(abs.(beta_L.-beta_1))) # beta_1 was defined earlier and has to be the same as beta_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2186e55",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0aaf55",
   "metadata": {},
   "source": [
    "TODO : find interesting problem with confirmed (known / analytic) result to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff3850",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84b1708b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module SaveLoadTxt.\n",
      "WARNING: using SaveLoadTxt.dump_txt in module Main conflicts with an existing identifier.\n",
      "WARNING: using SaveLoadTxt.load_txt in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "include(\"../../comp_translate/SaveLoadTxt.jl\") # Assuming you have a SaveLoadTxt.jl file with the necessary functions\n",
    "using .SaveLoadTxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd21a2c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92e06902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n, p = 100, 50\n",
    "Random.seed!(42)\n",
    "X = randn(n, p) # send to txt\n",
    "sigma = 0.1\n",
    "y = X * randn(p) + sigma * randn(n) # send to txt\n",
    "λ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc6ec3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round-trip OK \n"
     ]
    }
   ],
   "source": [
    "dump_txt(\"../../comp_translate/data/ISTA.txt\", [X, y]; append = false)\n",
    "\n",
    "loaded = load_txt(\"../../comp_translate/data/ISTA.txt\")\n",
    "@assert loaded == [X,y]\n",
    "println(\"Round-trip OK \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b308bcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " [-0.36335748145177754 1.7081843190508057 … -0.263208317752874 -0.6082027770693206; 0.2517372155742292 -1.0310474066155366 … 1.7649065326617626 -1.1552930517326399; … ; 0.3682069358154837 -1.529323847225266 … 1.506239239185287 0.8232577070328778; -0.04656094092083756 -0.19509907821117517 … 0.17077303483751144 0.1123281811728438]\n",
       " [-2.4522781251524863, 12.178350834823886, 4.57918453777345, 6.4743636007976235, -5.362304725560138, -1.5621900454469952, 5.104743872498451, -7.681676891856984, -7.023808087048749, 6.1632229078781195  …  -8.185326480885738, -4.813068524860786, -5.422785548383902, -8.529954505127906, 5.896744823913999, 4.339228886005578, 15.502578253982156, -16.028233010456333, -7.632580130984141, 2.550842146325011]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_txt(\"../../comp_translate/data/ISTA.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4744cdf",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40271875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ISTA] iter     1  cost=7.895e+02  diff=1.733e+03\n",
      "[ISTA] END iter   259  cost=4.280e+00  diff=9.353e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50-element Vector{Float64}:\n",
       " -0.22168095244552247\n",
       " -0.8107653026832372\n",
       "  1.2197383161992026\n",
       "  2.1296535700264316\n",
       "  0.8582163017697456\n",
       " -0.3170644602288678\n",
       "  0.6493981399795815\n",
       " -0.27916298733368494\n",
       "  1.1051369784749918\n",
       " -0.11074684894907925\n",
       "  ⋮\n",
       "  0.26028307597754174\n",
       "  2.00004079306363\n",
       " -0.2744035476875923\n",
       " -1.1161825448531286\n",
       " -1.231318053803642\n",
       "  0.11211515350120801\n",
       " -0.9711088091666977\n",
       " -0.329614416022857\n",
       " -0.15895911615979455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f(b) = 0.5*norm(y-X*b,2)^2\n",
    "∇f(b) = -X'*(y - X*b)\n",
    "g(x) = λ*sum(abs, x) # L1 norm\n",
    "prox_L(x, step) = sign.(x) .* max.(abs.(x) .- λ*step, zero(x))\n",
    "\n",
    "beta0 = zeros(p)# initial conditions\n",
    "\n",
    "beta_L = ista_L(beta0, f, g, ∇f, opnorm(X)^2, prox_L, tol=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a80c7",
   "metadata": {},
   "source": [
    "# General function BackTrack *(f, g, $L_0$, prox given)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561e2d0",
   "metadata": {},
   "source": [
    "If we known the gradient of f is L-Lipschitz but without an explicit expression (or even majoration) of L we can do backtracking.  \n",
    "\n",
    "We start with a small L0 (<span style=\"color:red\"><b>TODO :</b></span> trouver une manière de le faire) and at each iteration according to some conditions we can improve the constant used to be more precise until the convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0681b",
   "metadata": {},
   "source": [
    "For any $\\gamma>0$ and $y\\in\\mathbb R^{n}$ we define\n",
    "$$\n",
    "\\mathcal Q_\\gamma(x,y):=\n",
    "f(y)+\\langle x-y,\\nabla f(y)\\rangle+\\frac1{2\\gamma}\\|x-y\\|_2^2+g(x)\n",
    "$$\n",
    "\n",
    "Minimising this quadratic yields the point\n",
    "\n",
    "$$\n",
    "P_\\gamma(y):=\\operatorname*{argmin}_{x\\in\\mathbb R^{n}},\n",
    "\\mathcal Q_\\gamma(x,y)\n",
    "=\\operatorname{prox}_{\\gamma g}\\bigl(y-\\gamma\\nabla f(y)\\bigr)\n",
    "$$\n",
    "\n",
    "From *Lemma 2.3*, we have the test,\n",
    "> A Fast Iterative Shrinkage-Thresholding Algorithm\n",
    "for Linear Inverse Problems.  \n",
    "Amir Beck and Marc Teboulle\n",
    " \n",
    "\n",
    "$$\n",
    "F\\bigl(P_\\gamma(y)\\bigr)\\le\\mathcal Q_\\gamma\\bigl(P_\\gamma(y),y\\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3009c91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ista (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function ista(x0, f, g, ∇f, L0, prox;\n",
    "        eta = 2.0, max_iter = 100_000,tol= 1e-9,print_freq = 1000,verbose = true)\n",
    "\n",
    "    x  = copy(x0)\n",
    "    x_new  = similar(x)\n",
    "    F_prev = f(x) + g(x) # coût initial\n",
    "    F_new = 0\n",
    "    L      = L0\n",
    "\n",
    "    for k in 1:max_iter\n",
    "        grad = ∇f(x)\n",
    "\n",
    "        L_trial = L\n",
    "        while true\n",
    "            step = 1/L_trial\n",
    "            x_new .= prox(x .- step .* grad, step)\n",
    "\n",
    "            diff = x_new .- x\n",
    "            f_new = f(x_new)\n",
    "            g_new = g(x_new)\n",
    "            F_new = f_new + g_new\n",
    "\n",
    "            Q_val = f(x) + dot(diff, grad) + (L_trial/2) * dot(diff, diff) + g_new  # majorant\n",
    "\n",
    "            F_new ≤ Q_val + eps() && break # critère BT\n",
    "            L_trial *= eta\n",
    "            if L_trial > 1e12                 \n",
    "                error(\"Backtracking diverged : L trop grand\")\n",
    "            end\n",
    "        end\n",
    "        L = L_trial                            # prochain tour part de L_trial\n",
    "\n",
    "        if verbose && (k == 1 || k % print_freq == 0)\n",
    "            @printf(\"[ISTA-BT] iter %6d  cost = %.3e  ΔF = %.3e  L = %.3e\\n\",\n",
    "                    k, F_new, abs(F_prev - F_new), L)\n",
    "        end\n",
    "        if abs(F_prev - F_new) < tol \n",
    "            if verbose\n",
    "                @printf(\"[ISTA-BT] END iter %5d  cost=%.3e  diff=%.3e\\n\", k, F_new, abs(F_prev - F_new))\n",
    "            end\n",
    "            return x_new\n",
    "        end\n",
    "\n",
    "        x .= x_new\n",
    "        F_prev = F_new\n",
    "    end\n",
    "    return x\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094fd8b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2d345c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n, p = 100, 50\n",
    "Random.seed!(42)\n",
    "X = randn(n, p)\n",
    "sigma = 0.1\n",
    "y = X * randn(p) + sigma * randn(n)\n",
    "λ = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af8cab",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22c39971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Différence entre beta_L et beta_BT : 1.990740268853486e-6\n"
     ]
    }
   ],
   "source": [
    "f(b) = 0.5*norm(y-X*b,2)^2\n",
    "∇f(b) = -X'*(y - X*b)\n",
    "g(x) = λ*sum(abs, x) # L1 norm\n",
    "prox_L(x, step) = sign.(x) .* max.(abs.(x) .- λ*step, zero(x))\n",
    "L0 = 0.0001 # small L0; assuem we don't know the real value of L\n",
    "\n",
    "beta0 = zeros(p)# initial conditions\n",
    "beta_BT = ista(beta0, f, g, ∇f, L0, prox_L, eta=2, tol=1e-9, verbose = false)\n",
    "\n",
    "println(\"Différence entre beta_L et beta_BT : \", maximum(abs.(beta_L.-beta_BT))) # beta_1 was defined earlier and has to be the same as beta_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6658f",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4733fc3",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29ea48c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " [-0.36335748145177754 1.7081843190508057 … -0.263208317752874 -0.6082027770693206; 0.2517372155742292 -1.0310474066155366 … 1.7649065326617626 -1.1552930517326399; … ; 0.3682069358154837 -1.529323847225266 … 1.506239239185287 0.8232577070328778; -0.04656094092083756 -0.19509907821117517 … 0.17077303483751144 0.1123281811728438]\n",
       " [-2.4522781251524863, 12.178350834823886, 4.57918453777345, 6.4743636007976235, -5.362304725560138, -1.5621900454469952, 5.104743872498451, -7.681676891856984, -7.023808087048749, 6.1632229078781195  …  -8.185326480885738, -4.813068524860786, -5.422785548383902, -8.529954505127906, 5.896744823913999, 4.339228886005578, 15.502578253982156, -16.028233010456333, -7.632580130984141, 2.550842146325011]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n, p = 100, 50\n",
    "Random.seed!(42)\n",
    "sigma = 0.1\n",
    "λ = 0.1\n",
    "L0 = 0.0001 # small L0; assume we don't know the real value of L\n",
    "X, y = load_txt(\"../../comp_translate/data/ISTA.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7448c",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d6f5227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ISTA-BT] iter      1  cost = 5.510e+02  ΔF = 1.972e+03  L = 2.097e+02\n",
      "[ISTA-BT] END iter   190  cost=4.280e+00  diff=9.837e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50-element Vector{Float64}:\n",
       " -0.22167995333563506\n",
       " -0.8107652522629043\n",
       "  1.2197375579068204\n",
       "  2.1296538608835527\n",
       "  0.8582167300402902\n",
       " -0.3170641266586662\n",
       "  0.649398776181477\n",
       " -0.2791640098707406\n",
       "  1.1051361208805932\n",
       " -0.11074599258859008\n",
       "  ⋮\n",
       "  0.26028289521126513\n",
       "  2.00004090705919\n",
       " -0.2744025520117581\n",
       " -1.1161821692284422\n",
       " -1.2313182193942989\n",
       "  0.1121157896388718\n",
       " -0.9711074507853379\n",
       " -0.3296148198074906\n",
       " -0.15895951290181398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f(b) = 0.5*norm(y-X*b,2)^2\n",
    "∇f(b) = -X'*(y - X*b)\n",
    "g(x) = λ*sum(abs, x) # L1 norm\n",
    "prox_L(x, step) = sign.(x) .* max.(abs.(x) .- λ*step, zero(x))\n",
    "\n",
    "beta0 = zeros(p)# initial conditions\n",
    "\n",
    "beta_L = ista(beta0, f, g, ∇f, L0, prox_L, eta=2, tol=1e-9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
